---
title: "Exercise quality prediction"
author: "Frederico Caram"
date: "27 de dezembro de 2015"
output: html_document
---

Load librarys and set the seed to make it reproducible
```{r, echo=FALSE, message=FALSE, warning=FALSE}
require("randomForest")
require("gbm")
require("e1071")
require("caret")
set.seed(9876)
```

## Load, clean and slice the data

Load the data
```{r, message=FALSE, warning=FALSE}
data_set <- read.csv('pml-training.csv', header = TRUE, na.strings=c("NA", "#DIV/0!"))
testing_set <- read.csv('pml-testing.csv', header = TRUE, na.strings=c("NA", "#DIV/0!"))
```

All variables with at least one “NA” were excluded from the analysis
```{r, message=FALSE, warning=FALSE}
data_clr <- data_set[, apply(data_set, 2, function(x) !any(is.na(x)))]
```

Variables related to time and user information were excluded
```{r, message=FALSE, warning=FALSE}
data_clr <- data_clr[,-c(1:8)]
```

The data cleaning resulted in 52 variables and 19622 class measurements.

Remove the same variables from testing set
```{r, message=FALSE, warning=FALSE}
testing_clr <- testing_set[,names(data_clr[,-52])]
```

Creates the cross-validation set (70% for training and 30% for testing, for a 19k dataset)
```{r, message=FALSE, warning=FALSE}
inTrain <- createDataPartition(data_clr$classe, p = 0.7, list = FALSE)
training <- data_clr[inTrain,]
cross_validation <- data_clr[-inTrain,]
```

#Cross validation testing

For this prediction Random forest trees were generated for the training dataset using cross-validation. Then it was examined under the sliced training set to examine the accuracy and estimated errors for the prediction. 

```{r, message=FALSE, warning=FALSE, echo=FALSE}
fitControl <- trainControl(method="cv", number = 5, allowParallel = TRUE, verbose = FALSE)
rffit <- train(classe ~ ., data=training, method = "rf", trControl = fitControl, verbose = FALSE)
predrf<-predict(rffit, newdata=cross_validation)
```
```{r, message=FALSE, warning=FALSE}
confusionMatrix(predrf, cross_validation$classe)
```
By using 51 predictors for five classes using cross-validation at a 5-fold an accuracy of 99.42% with a 95% CI [0.9919-0.996] was achieved accompanied by a Kappa value of 0.9927.

The same tests were also executed in a Boosting algorithm for comparison:
```{r, message=FALSE, warning=FALSE}
fitControl2<-trainControl(method="cv", number=5, allowParallel=TRUE, verbose=FALSE)
gmbfit<-train(classe~.,data=training, method="gbm", trControl=fitControl2, verbose=FALSE)
predgmb<-predict(gmbfit, newdata=cross_validation)
confusionMatrix(predgmb, cross_validation$classe)
```

As we can see the boosting algorithm performed poorer with an accuracy of only 96.47%

## Results
Get the predictions for the test cases provided

```{r, message=FALSE, warning=FALSE}
predictions <- predict(rffit, newdata = testing_clr)
# Output for the prediction of the 20 cases provided
predictions
```

Once, the predictions were obtained for the 20 test cases provided, the below shown script was used to obtain single text files to be uploaded to the courses web site to comply with the submission assigment. 20 out of 20 hits also confirmed the accuracy of the obtained models.
```{r, message=FALSE, warning=FALSE}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(predictions)
```