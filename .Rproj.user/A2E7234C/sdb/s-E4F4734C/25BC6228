{
    "contents" : "---\ntitle: \"Exercise quality prediction\"\nauthor: \"Frederico Caram\"\ndate: \"27 de dezembro de 2015\"\noutput: html_document\n---\n\nLoad librarys and set the seed to make it reproducible\n```{r, echo=FALSE, message=FALSE, warning=FALSE}\nrequire(\"randomForest\")\nrequire(\"gbm\")\nrequire(\"e1071\")\nrequire(\"caret\")\nset.seed(9876)\n```\n\n## Load, clean and slice the data\n\nLoad the data\n```{r, message=FALSE, warning=FALSE}\ndata_set <- read.csv('pml-training.csv', header = TRUE, na.strings=c(\"NA\", \"#DIV/0!\"))\ntesting_set <- read.csv('pml-testing.csv', header = TRUE, na.strings=c(\"NA\", \"#DIV/0!\"))\n```\n\nAll variables with at least one “NA” were excluded from the analysis\n```{r, message=FALSE, warning=FALSE}\ndata_clr <- data_set[, apply(data_set, 2, function(x) !any(is.na(x)))]\n```\n\nVariables related to time and user information were excluded\n```{r, message=FALSE, warning=FALSE}\ndata_clr <- data_clr[,-c(1:8)]\n```\n\nThe data cleaning resulted in 52 variables and 19622 class measurements.\n\nRemove the same variables from testing set\n```{r, message=FALSE, warning=FALSE}\ntesting_clr <- testing_set[,names(data_clr[,-52])]\n```\n\nCreates the cross-validation set (70% for training and 30% for testing, for a 19k dataset)\n```{r, message=FALSE, warning=FALSE}\ninTrain <- createDataPartition(data_clr$classe, p = 0.7, list = FALSE)\ntraining <- data_clr[inTrain,]\ncross_validation <- data_clr[-inTrain,]\n```\n\n#Cross validation testing\n\nFor this prediction Random forest trees were generated for the training dataset using cross-validation. Then it was examined under the sliced training set to examine the accuracy and estimated errors for the prediction. \n\n```{r, message=FALSE, warning=FALSE, echo=FALSE}\nfitControl <- trainControl(method=\"cv\", number = 5, allowParallel = TRUE, verbose = FALSE)\nrffit <- train(classe ~ ., data=training, method = \"rf\", trControl = fitControl, verbose = FALSE)\npredrf<-predict(rffit, newdata=cross_validation)\n```\n```{r, message=FALSE, warning=FALSE}\nconfusionMatrix(predrf, cross_validation$classe)\n```\nBy using 51 predictors for five classes using cross-validation at a 5-fold an accuracy of 99.42% with a 95% CI [0.9919-0.996] was achieved accompanied by a Kappa value of 0.9927.\n\nThe same tests were also executed in a Boosting algorithm for comparison:\n```{r, message=FALSE, warning=FALSE}\nfitControl2<-trainControl(method=\"cv\", number=5, allowParallel=TRUE, verbose=FALSE)\ngmbfit<-train(classe~.,data=training, method=\"gbm\", trControl=fitControl2, verbose=FALSE)\npredgmb<-predict(gmbfit, newdata=cross_validation)\nconfusionMatrix(predgmb, cross_validation$classe)\n```\n\nAs we can see the boosting algorithm performed poorer with an accuracy of only 96.47%\n\n## Results\nGet the predictions for the test cases provided\n\n```{r, message=FALSE, warning=FALSE}\npredictions <- predict(rffit, newdata = testing_clr)\n# Output for the prediction of the 20 cases provided\npredictions\n```\n\nOnce, the predictions were obtained for the 20 test cases provided, the below shown script was used to obtain single text files to be uploaded to the courses web site to comply with the submission assigment. 20 out of 20 hits also confirmed the accuracy of the obtained models.\n```{r, message=FALSE, warning=FALSE}\npml_write_files = function(x){\n  n = length(x)\n  for(i in 1:n){\n    filename = paste0(\"problem_id_\",i,\".txt\")\n    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)\n  }\n}\npml_write_files(predictions)\n```",
    "created" : 1451226918324.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2495084477",
    "id" : "25BC6228",
    "lastKnownWriteTime" : 1451239409,
    "path" : "~/R/Projects/Practical Machine Learning/ExerciseQualityPrediction.Rmd",
    "project_path" : "ExerciseQualityPrediction.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_markdown"
}